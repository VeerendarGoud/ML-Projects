{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2jh2XfDPsVPkEKk4oIWwy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VeerendarGoud/ML-Projects/blob/master/Pyspark_NLP_Topic_modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_1P7mU_Bo7Uh"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install java\n",
        "\n",
        "!apt-get install -y openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "metadata": {
        "id": "nmm-ZqzMpJ7E"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup java environment vars\n",
        "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
        "os.environ['PATH'] = os.environ['JAVA_HOME'] + '/bin:' + os.environ['PATH']"
      ],
      "metadata": {
        "id": "s7hBCVwbpWLL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!java -version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byc4Evh_p2Cv",
        "outputId": "6cf67bcc-342c-4bab-af77-cef0377956ad"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"1.8.0_382\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_382-8u382-ga-1~22.04.1-b05)\n",
            "OpenJDK 64-Bit Server VM (build 25.382-b05, mixed mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $JAVA_HOME"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nroa39pzyBLj",
        "outputId": "9b70c16f-36d2-4bce-f9d8-88df488ed791"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/jvm/java-8-openjdk-amd64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install pyspark\n",
        "!pip install pyspark==3.3.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOX6GTKyp4lg",
        "outputId": "f0f7a82f-400d-4ad1-f674-841c1c9a79f6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==3.3.0\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.3/281.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5 (from pyspark==3.3.0)\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764004 sha256=44fd9c20a70f73d2277fd42f9a22c8a3954e117a089837e2a1f1e11722c08f61\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/9c/6c/d5200fcf351ffa39cbe09911e99703283624cd037df58070d9\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install spark NLP\n",
        "!pip install spark-nlp==5.0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoTNTW5Ct9Gd",
        "outputId": "d073884b-34cd-463e-a62d-12bec868289e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spark-nlp==5.0.2\n",
            "  Downloading spark_nlp-5.0.2-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/502.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m501.8/502.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.1/502.1 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-5.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall spark-nlp pyspark -y"
      ],
      "metadata": {
        "id": "6moYVmQ4zAyC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Install nltk\n",
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrHdd9MmuGMS",
        "outputId": "ead2e25e-5647-46dc-e676-e73a82b79160"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dwonload the data from here\n",
        "# https://www.kaggle.com/datasets/eswarchandt/amazon-music-reviews"
      ],
      "metadata": {
        "id": "Fv7fdNcUu5-F"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/archive.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gh_xOTASuLB1",
        "outputId": "a545b845-fad7-4e32-ecb6-4f8aae457bd0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/archive.zip\n",
            "  inflating: Musical_Instruments_5.json  \n",
            "  inflating: Musical_instruments_reviews.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark"
      ],
      "metadata": {
        "id": "oIZPXFv7v-MA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hWneBjSDwAbs",
        "outputId": "c99b9df0-61db-41e6-f3bf-93c3ff3b1ea1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.3.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys"
      ],
      "metadata": {
        "id": "InkwbKsvvNQH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "p2W9bMm_vOsd",
        "outputId": "8633ef12-225e-4e1b-8d26-a8e4cef86229"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sparknlp\n",
        "\n",
        "\n",
        "# sparknlp.version()\n",
        "\n"
      ],
      "metadata": {
        "id": "1NPIG9kXuzNJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = sparknlp.start()"
      ],
      "metadata": {
        "id": "qhLQZCD50Ewc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pyspark import SparkConf, SparkContext\n",
        "# sc = SparkContext.getOrCreate()"
      ],
      "metadata": {
        "id": "i0l5he_PxivO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Load the data\n",
        "data_path = '/content/Musical_instruments_reviews.csv'\n",
        "data = spark.read.csv(data_path, header=True)"
      ],
      "metadata": {
        "id": "RNCRiuNm0KyH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data info\n",
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T_WThZG0Kvq",
        "outputId": "890d4ae7-4148-4ff8-f7c0-eaf9855555af"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['reviewerID',\n",
              " 'asin',\n",
              " 'reviewerName',\n",
              " 'helpful',\n",
              " 'reviewText',\n",
              " 'overall',\n",
              " 'summary',\n",
              " 'unixReviewTime',\n",
              " 'reviewTime']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fYfmj9KB0Ks3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_col = 'reviewText'\n",
        "review_text = data.select(text_col).filter(F.col(text_col).isNotNull())"
      ],
      "metadata": {
        "id": "rpzpwnwb0KqV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_text.limit(5).show(truncate=90)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zg-cQJWt0Knw",
        "outputId": "68e5b6c6-fb93-4e4b-c2c2-aa5fba1b546a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------------------------------------------+\n",
            "|                                                                                reviewText|\n",
            "+------------------------------------------------------------------------------------------+\n",
            "|                                                                          that's just like|\n",
            "|The product does exactly as it should and is quite affordable.I did not realized it was...|\n",
            "|The primary job of this device is to block the breath that would otherwise produce a po...|\n",
            "|Nice windscreen protects my MXL mic and prevents pops. Only thing is that the gooseneck...|\n",
            "|This pop filter is great. It looks and performs like a studio filter. If you're recordi...|\n",
            "+------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spark NLP Pipeline"
      ],
      "metadata": {
        "id": "eo7NMvt805sL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PerceptronModel.pretrained"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcMxNl7o9TMq",
        "outputId": "b54f406f-4b1e-428e-8ef9-16a74560b368"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pos_anc download started this may take some time.\n",
            "Approximate size to download 3.9 MB\n",
            "[OK!]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "POS_dbb704204f6f"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sparknlp\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.ml import Pipeline"
      ],
      "metadata": {
        "id": "Woiy3EoX2nl5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "from sparknlp.base import DocumentAssembler\n",
        "\n",
        "document_assembler = DocumentAssembler() \\\n",
        "                        .setInputCol('reviewText') \\\n",
        "                        .setOutputCol('document')"
      ],
      "metadata": {
        "id": "v4n2PHIQ0Kll"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer\n",
        "\n",
        "from sparknlp.annotator import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "            .setInputCols(['document']) \\\n",
        "            .setOutputCol('tokenized')"
      ],
      "metadata": {
        "id": "0vhVCwGj0Ki_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizer\n",
        "\n",
        "from sparknlp.annotator import Normalizer\n",
        "\n",
        "normalizer = Normalizer()\\\n",
        "            .setInputCols(['tokenized'])\\\n",
        "            .setOutputCol('normalized') \\\n",
        "            .setLowercase(True)"
      ],
      "metadata": {
        "id": "g7tSYlKR0Kgr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization\n",
        "\n",
        "from sparknlp.annotator import LemmatizerModel\n",
        "\n",
        "lemmatizer = LemmatizerModel.pretrained()\\\n",
        "            .setInputCols(['normalized']) \\\n",
        "            .setOutputCol('lemmatized')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L87J717r0KeG",
        "outputId": "dfcc1e91-29c2-4154-bf7d-dacd8cb84163"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemma_antbnc download started this may take some time.\n",
            "Approximate size to download 907.6 KB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download stop words\n",
        "\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "eng_stopwords = stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuHrigsE0KbN",
        "outputId": "f2ac6498-01ad-48aa-97a3-5f1aaaf5393b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# StopWords cleaner\n",
        "\n",
        "from sparknlp.annotator import StopWordsCleaner\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "                .setInputCols(['lemmatized']) \\\n",
        "                .setOutputCol('unigram') \\\n",
        "                .setStopWords(eng_stopwords)"
      ],
      "metadata": {
        "id": "t52_OpPG0KZF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NGram\n",
        "# In addition to unigrams, it is good to use n-grams for topic\n",
        "# modelling as well since they help to better refine topics.\n",
        "\n",
        "from sparknlp.annotator import NGramGenerator\n",
        "\n",
        "ngrammer = NGramGenerator()\\\n",
        "            .setInputCols(['lemmatized'])\\\n",
        "            .setOutputCol('ngram') \\\n",
        "            .setN(3) \\\n",
        "            .setEnableCumulative(True)\\\n",
        "            .setDelimiter('_')"
      ],
      "metadata": {
        "id": "h5d8msfi0KWN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#POS\n",
        "from sparknlp.annotator import PerceptronModel\n",
        "\n",
        "pos_tagger = PerceptronModel.pretrained('pos_anc') \\\n",
        "            .setInputCols(['document', 'lemmatized']) \\\n",
        "            .setOutputCol('pos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgUtZqB_0KTZ",
        "outputId": "6363be0b-cede-4d88-f265-f7fa7dc25391"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pos_anc download started this may take some time.\n",
            "Approximate size to download 3.9 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp.base import Finisher\n",
        "\n",
        "finisher = Finisher() \\\n",
        "     .setInputCols(['unigram', 'ngram', 'pos'])"
      ],
      "metadata": {
        "id": "aw2AFjAP0KQq"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Pipeline\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "pipeline = Pipeline() \\\n",
        "            .setStages([\n",
        "                document_assembler,\n",
        "                 tokenizer,\n",
        "                 normalizer,\n",
        "                 lemmatizer,\n",
        "                 stopwords_cleaner,\n",
        "                 pos_tagger,\n",
        "                 ngrammer,\n",
        "                 finisher\n",
        "            ])"
      ],
      "metadata": {
        "id": "XLMgOr4n0KN8"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_review = pipeline.fit(review_text).transform(review_text)"
      ],
      "metadata": {
        "id": "M-XmpM_o0KLR"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_review.limit(5).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDM7K7PA0KIp",
        "outputId": "4dd7f7b6-0d8a-4e92-a64c-840c843860f8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|          reviewText|    finished_unigram|      finished_ngram|        finished_pos|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|    that's just like|              [like]|[that, just, like...|        [IN, RB, IN]|\n",
            "|The product does ...|[product, exactly...|[the, product, do...|[DT, NN, VBP, RB,...|\n",
            "|The primary job o...|[primary, job, de...|[the, primary, jo...|[DT, JJ, NN, IN, ...|\n",
            "|Nice windscreen p...|[nice, windscreen...|[nice, windscreen...|[JJ, NN, NN, NNP,...|\n",
            "|This pop filter i...|[pop, filter, gre...|[this, pop, filte...|[DT, NN, NN, VB, ...|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-E-cEGlJ8ijL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}